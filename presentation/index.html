<!doctype html>
<html lang="en">

	<head>
		<meta charset="utf-8">

		<title>reveal.js - The HTML Presentation Framework</title>

		<meta name="description" content="A framework for easily creating beautiful presentations using HTML">
		<meta name="author" content="Hakim El Hattab">

		<meta name="apple-mobile-web-app-capable" content="yes" />
		<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />

		<link rel="stylesheet" href="css/reveal.css">
		<link rel="stylesheet" href="css/theme/default.css" id="theme">

		<!-- For syntax highlighting -->
		<link rel="stylesheet" href="lib/css/zenburn.css">

		<!-- If the query includes 'print-pdf', use the PDF print sheet -->
		<script>
			document.write( '<link rel="stylesheet" href="css/print/' + ( window.location.search.match( /print-pdf/gi ) ? 'pdf' : 'paper' ) + '.css" type="text/css" media="print">' );
		</script>

		<!--[if lt IE 9]>
		<script src="lib/js/html5shiv.js"></script>
		<![endif]-->
	</head>

	<body>

		<div class="reveal">

			<!-- Any section element inside of this container is displayed as a slide -->
			<div class="slides">
				<section data-markdown>
					<script type="text/template">
            ## Installation 

            * Make sure you have luigi, folium, pandas as scikit-learn installed. 

            * `pip install luigi`
            * `pip install folium`

					</script>
				</section>
				<section data-markdown>
					<script type="text/template">
						## Building your first Data Pipelines

						PyData DC Workshop 

						Presenter: @hunter_owens

					</script>
				</section>

				<section data-markdown>
					<script type="text/template">
						## Why you need a data pipeline

						* Organize your workflow 

						* Edit and Rerun 

						* Collaboration

					</script>
				</section>

				<section data-markdown>
					<script type="text/template">
						## Data Pipeline Tools

            * Make

            * Shell Scripts

            * Python Scripts

            * Drake 

            * AWS Toolkit

            * Luigi! 

					</script>
				</section>


				<section data-markdown>
					<script type="text/template">
            ## Why Luigi

            * All Python 

            * Produces an Analytic Graph 

            * Easy to collaborate on 

            * Scales well across diverse Datasources - Hadoop, Python, Postgres, etc! 

					</script>
				</section>
        
        <section data-markdown>
					<script type="text/template">
            ## Luigi First Principles 
            [](!https://raw.githubusercontent.com/spotify/luigi/master/doc/luigi.png)
            
					</script>
        </section>

        <section data-markdown>
          <script type="text/template">
            ## Atomic File Operations  
            A scripted data pipeline probably looks a bit like this. 

            ```
            from codebase import generate_features, fit_model, deploy_predictions

            if __name__ == '__main__':
              generate_features()
              fit_model()
              deploy_predictions()

            ```
          </script>
        </section>
        
        <section data-markdown>
          <script type="text/template">
            ## Stuff breaks. 

            **All the time.**

            ```
            In [1]: fit_model()
            ---------------------------------------------------------------------------
            NameError                                 Traceback (most recent call last)
            <ipython-input-1-1ff42fe6f9be> in <module>()
            ----> 1 fit_model()

            NameError: name 'fit_model' is not defined

            ```
          </script>
        </section>

        <section data-markdown>
          <script type="text/template">
            ## So.... 
            What happens when this breaks. 

            at 2am. 

            when the model needs to be updated. 

            and we've already run 3 hours of calculations. 
          </script>
        </section>

        
        <section data-markdown>
          <script type="text/template">
            ## Resume at Broken Step 
            * Failures will happen, in both development and production. 

            * Resuming allows use to make atomic operations, only run code that needs to be rerun 

            * The idea of Atomic File or Database operations allows use to resume from last working step. 

          </script>
        </section>

        <section data-markdown>
          <script type="text/template">
            ## Atomic File Operations 
            Now, let's add some atomic file ops. 

            ```
            from codebase import generate_features, fit_model, deploy_predictions
            import os 

            if __name__ == '__main__':
              if not os.path.exists('./data/features.csv'):  
                generate_features()
                if not os.path.exists('model.pickle')
                  fit_model()
              if predictions.date != datetime.datetime.now():    
                deploy_predictions()

            ```
          </script>
        </section>

        <section data-markdown>
          <script type="text/template">
            ## Tasks and Targets 

            1) Tasks: A atomic unit of work. Takes a target(s), produces (targets)

            2) Targets: Python representation of a saved state of data or other information. 

          </script>
        </section>
        
        <section data-markdown>
          <script type="text/template">
            ## Our first Task 
            
            ```
            import luigi 

            class MyTask(luigi.Task):

              param = luigi.parameter(default=42)

              def requires(self):
                ### This is what the task depends on befor it runs. 
                return SomeOtherTask(self.param)

              def run(self):
                ### This is the code that is executed. 
                f = self.output().open('w')
                f.write("hello world from run")
                f.close()

              def output(self):
                ### this is the target we are writing to. 
                return luigi.LocalTarget('/tmp/foo/bar-%s.txt' % self.param)
            ```
          </script>
        </script>
        </section>
        
        <section data-markdown>
          <script type="text/template">
            ## Target Types 
            * LocalTarget
            * S3
            * PostgresTable
            * HDFS File
            * BigQuery
            * And more! 

          </script>
        </script>
        </section>
        <section data-markdown>
          <script type="text/template">
            ## Running it 
            
            ### Command Line 

            `luigi --module my_module MyTask --param 42 --local-scheduler`


            ### Luigi Daemon 
            `luigid background`
            `luigi --module my_module MyTask`

            Check status by visiting `localhost:8082` if running the daemon
            
            ### As a script/inside Juypter Notebooks
            ```
            if __name__ == '__main__':
              luigi.run(['MyTaskName', '--local-scheduler'])
            ```
          </script>
        </script>
        </section>

        <section data-markdown>
          <script type="text/template">
            ## Pandas Integration  
            (*or really any other pickle-able object*)
            ```
            import luigi 
            import pandas as pd

            class OutputDF(luigi.ExternalTask):

              def run(self):
                df = pd.DataFrame()
                # get the file 
                f = self.output().open('w')
                # send the pickle to the target
                pickle = df.to_pickle(f)
                # close us out 
                f.close()

              def output(self):
                ### this is the target we are writing to. 
                return luigi.localTarget('/tmp/df.pickle')

            class readDf(luigi.task):

              def requires(self):
                return OutputDF()

              def run(self)
                df = pickle.load(self.input().open('r'))

              def output(self):

            ```
          </script>
        </script>
        </section>
        
        <section data-markdown>
          <script type="text/template">
            ## Let's Build Our Pipeline

             * Go to http://bit.ly/pydata-dc-pipelines 
             * clone the repo 
             * look for the `dc-pipeline.py` file. 
        
          </script>
        </section>

        <section data-markdown>
          <script type="text/template">
            ## Example Data Insert - PSQL  


            ```python

            class ResultsetToDatabase(luigi.postgres.CopyToTable):
                date_interval = luigi.DateIntervalParameter()

                columns = [("date_from", "DATE"),
                           ("date_to", "DATE"),
                           ("artist", "TEXT"),
                           ("streams", "INT")]

                def requires(self):
                    return SomeOtherJob()
            ```
            </script>
        </section>

        <section data-markdown>
          <script type="text/template">
            ## Example Data Query - PSQL

            ```python

            class ResultsetToDatabase(luigi.postgres.Query):
                date_interval = luigi.DateIntervalParameter()

                columns = [("date_from", "DATE"),
                           ("date_to", "DATE"),
                           ("artist", "TEXT"),
                           ("streams", "INT")]

                query = "SELECT * FROM table_name WHERE artist = 'The Postal Service'"

                def requires(self):
                return SomeOtherJob()
              ```
          </script>
        </section>
        <section data-markdown>
          <script type="text/template">
            ## Batch Data Job - Spark 
            ```
            class PySparkWordCount(SparkSubmitTask):
                """
                Submits a Word Count Job to spark, using s3. Fancy, right?

                Example luigi configuration::
                    [spark]
                    spark-submit: /usr/local/spark/bin/spark-submit
                    master: spark://spark.example.org:7077
                    deploy-mode: client
                """
                driver_memory = '2g'
                executor_memory = '3g'
                total_executor_cores = luigi.IntParameter(default=100, significant=False)

                name = "PySpark Word Count"
                app = 'wordcount.py'

                def app_options(self):
                    # These are passed to the Spark main args in the defined order.
                    return [self.input().path, self.output().path]

                def input(self):
                    return S3Target("s3n://bucket.example.org/wordcount.input")

                def output(self):
                return S3Target('s3n://bucket.example.org/wordcount.output')
            ```
            </script>
        </section>
        
        <section data-markdown>
          <script type="text/template">
            ## Confiugration 
            * Allows you choose luigi server
            * store secrets
            * etc

            ```
            [hadoop]
            version=cdh4
            streaming-jar=/usr/lib/hadoop-xyz/hadoop-streaming-xyz-123.jar

            [core]
            default-scheduler-host=luigi-host.mycompany.foo
            error-email=foo@bar.baz
            ```
          </script>
        </section>

        <section data-markdown>
          <script type="text/template">
            ## Examples 
            * [Docs](http://luigi.readthedocs.com/)
            * [OpenEEMeter](https://github.com/openeemeter/etl)
            * [Spotify NYC Data Science Meetup Presenation](http://www.slideshare.net/erikbern/luigi-presentation-nyc-data-science)

          </script>
        </section>


        <section data-markdown>
          <script type="text/template">
            ## Thanks for coming!

            Comments, Concerns, Existential Data Crises: Hunter@hunterowens.net or @hunter_owens on the twitters. 
          </script>
        </section>
			</div>

		</div>

		<script src="lib/js/head.min.js"></script>
		<script src="js/reveal.min.js"></script>

		<script>

			// Full list of configuration options available here:
			// https://github.com/hakimel/reveal.js#configuration
			Reveal.initialize({
				controls: true,
				progress: true,
				history: true,

				theme: Reveal.getQueryHash().theme, // available themes are in /css/theme
				transition: Reveal.getQueryHash().transition || 'default', // default/cube/page/concave/zoom/linear/none

				// Optional libraries used to extend on reveal.js
				dependencies: [
					{ src: 'lib/js/classList.js', condition: function() { return !document.body.classList; } },
					{ src: 'plugin/markdown/showdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
					{ src: 'plugin/markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
					{ src: 'plugin/highlight/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } },
					{ src: 'plugin/zoom-js/zoom.js', async: true, condition: function() { return !!document.body.classList; } },
					{ src: 'plugin/notes/notes.js', async: true, condition: function() { return !!document.body.classList; } }
				]
			});

		</script>

	</body>
</html>
